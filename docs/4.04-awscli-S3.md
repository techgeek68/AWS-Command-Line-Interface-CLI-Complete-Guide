# AWS CLI — S3 Operations Guide

> Note: When running commands or instructions in PowerShell, do not forget to use `aws.exe`
---
**Bucket Operations**

**List buckets**

Syntax:
```bash
  aws s3 ls
```

**Create a bucket (recommended for non-us-east-1)**

Syntax:
```bash
aws s3api create-bucket \
  --bucket <BUCKET_NAME> \
  --region <REGION> \
  --create-bucket-configuration LocationConstraint=<REGION>
```
> For us-east-1, omit `--create-bucket-configuration`.

Examples:

Linux/Unix:
```bash
aws s3api create-bucket \
  --bucket my-unique-bucket-0825 \
  --region us-west-2 \
  --create-bucket-configuration LocationConstraint=us-west-2
```

For us-east-1, you omit the --create-bucket-configuration:
```bash
aws s3api create-bucket \
  --bucket my-unique-bucket-0826 \
  --region us-east-1
```

PowerShell:
```powershell
  aws s3api create-bucket --bucket my-unique-bucket-0827 --region us-west-2 --create-bucket-configuration LocationConstraint=us-west-2
```

For us-east-1:
```powershell
  aws s3api create-bucket --bucket my-unique-bucket-0828 --region us-east-1
```


**Get bucket location**

Syntax:
```bash
  aws s3api get-bucket-location --bucket <BUCKET_NAME>
```

Example:
```bash
  aws s3api get-bucket-location --bucket my-unique-bucket-0825
```

**Remove empty bucket**

Syntax:
```bash
  aws s3 rb s3://<BUCKET_NAME>
```

Example:
```bash
  aws s3 rb s3://my-unique-bucket-0825
```

**Force remove bucket and all contents (DANGEROUS)**
```bash
  aws s3 rb s3://<BUCKET_NAME> --force
```

---
**Object Operations**

**Upload a file to the bucket**

Syntax:
```bash
  aws s3 cp <LOCAL_FILE> s3://<BUCKET_NAME>/
```

Example:
```bash
  aws s3 cp myphoto.png s3://my-unique-bucket-0828
```

**List objects in a bucket/prefix**

Syntax:
```bash
aws s3 ls s3://<BUCKET_NAME>/<PREFIX>/
```

Examples:
```bash
  aws s3 ls s3://my-unique-bucket-0828
```
```bash
  aws s3 ls s3://my-unique-bucket-0828/images/          #Listing with prefix
```

**Download a file from the bucket**

Syntax:
```bash
  aws s3 cp s3://<BUCKET_NAME>/<OBJECT_KEY> <LOCAL_FILE>
```
Example:
```bash
  aws s3 cp s3://my-unique-bucket-0828/myphoto.png ./downloaded-photo.png
```

**Delete object**

Syntax:
```bash
  aws s3 rm s3://<BUCKET_NAME>/<OBJECT_KEY>
```
Example:
```bash
  aws s3 rm s3://my-unique-bucket-0828/myphoto.png
```

**Delete prefix recursively (DANGEROUS)**

Syntax:
```bash
  aws s3 rm s3://<BUCKET_NAME>/<PREFIX>/ --recursive
```
Example:
```bash
  aws s3 rm s3://my-unique-bucket-0828/images/ --recursive
```

**Generate Presign object URL (valid 1 hour)**
Generates a pre-signed URL to temporarily allow access to a private S3 object without changing its permissions.

Syntax:
```bash
  aws s3 presign s3://<BUCKET_NAME>/<OBJECT_KEY> --expires-in 3600
```
Example:
```bash
  aws s3 presign s3://my-unique-bucket-0828/myphoto.png --expires-in 3600
```

**Recursive upload a directory**

Syntax:
```bash
aws s3 cp <LOCAL_DIR>/ s3://<BUCKET_NAME>/<PREFIX>/ --recursive
```

Example:

Create a directory inside the S3 bucket.

PowerShell:
```powershell
  echo $null | aws.exe s3 cp - s3://my-unique-bucket-0828/project-data/
```
Linux/Unix:
```bash
  aws s3 cp /dev/null s3://my-unique-bucket-0828/project-data/
```

Create a directory with the same name on your local machine. and run the command:
```powershell
  aws s3 cp ./project-data s3://my-unique-bucket-0828/project-data/ --recursive
```

---
**Sync Operations**
The sync operation in Amazon S3 refers to the process of making the contents of a local directory and an S3 bucket (or a bucket prefix/"folder") match, by copying new or updated files from one location to the other.

  **What It Does:**
  - Copies files from the source to the destination.
  - Only copies files that are new or have changed (based on size and timestamp).
  - Does not re-upload or re-download unchanged files.
  - Can be used in both directions (local → S3 or S3 → local).
    
**Sync local directory to bucket**

Synatx: 
```bash
aws s3 sync <LOCAL_DIR>/ s3://<BUCKET_NAME>/<PREFIX>/
```

Example:
1. Create a Local directory
     mkdir BackupSync
        echo "This is file1" > BackupSync/file1.txt
        echo "This is file2" > BackupSync/file2.txt
   
3. Create a directory inside the S3 bucket.

PowerShell:
```powershell
  echo $null | aws.exe s3 cp - s3://my-unique-bucket-0828/Backsync-data/
```
Linux/Unix:
```bash
  aws s3 cp /dev/null s3://my-unique-bucket-0828/Backsync-data/
```

Sync:
```bash
  aws.exe s3 sync ./BackupSync s3://my-unique-bucket-0828/Backsync-data/
```

> Note: You must re-run the sync command to update the bucket with new or changed files in your local directory.

**Sync bucket to local directory**

Syntax:
```bash
  aws s3 sync s3://<BUCKET_NAME>/<PREFIX>/ <LOCAL_DIR>/
```
Example:
```bash
  aws s3 sync s3://my-unique-bucket-0828/data/ ./data-download/
```

**Exclude certain files when syncing**

Syntax:
```bash
  aws s3 sync <LOCAL_DIR>/ s3://<BUCKET_NAME>/ --exclude "<file_name>" --exclude "<file_name>"
```

Example:
```bash
  aws s3 sync ./project/ s3://my-unique-bucket-0828/ --exclude "*.log" --exclude "*.tmp"
```

**Dry run sync (preview changes)**

Syntax:
```bash
  aws s3 sync <LOCAL_DIR>/ s3://<BUCKET_NAME>/ --dryrun
```
Example:
```powershell
  aws.exe s3 sync ./BackupSync s3://my-unique-bucket-0828/BackupSync-data/ --dryrun
```

### Storage class on sync

| Storage Class                        | Durability    | Availability | Access Pattern                                                                | Cost                                          |
| ------------------------------------ | ------------- | ------------ | ----------------------------------------------------------------------------- | --------------------------------------------- |
| **STANDARD**                         | 99.999999999% | 99.99%       | Frequently accessed                                                           | Highest storage cost                          |
| **STANDARD\_IA** (Infrequent Access) | 99.999999999% | 99.9%        | Less frequent access                                                          | Lower storage cost, higher retrieval cost     |
| **ONEZONE\_IA**                      | 99.999999999% | 99.5%        | Less frequent access, single AZ                                               | Cheaper than STANDARD\_IA                     |
| **INTELLIGENT\_TIERING**             | 99.999999999% | 99.9%        | Automatically moves objects between frequent/infrequent tiers based on access | Optimized cost                                |
| **GLACIER**                          | 99.999999999% | N/A          | Archival, retrieval in minutes to hours                                       | Very low storage cost, retrieval cost applies |
| **GLACIER DEEP ARCHIVE**             | 99.999999999% | N/A          | Long-term archival, retrieval can take 12+ hours                              | Lowest storage cost                           |

Syntax:
```bash
  aws s3 sync <LOCAL_DIR>/ s3://<BUCKET_NAME>/ --storage-class <Storage_Class_Value>
```

Example:
```bash
  aws s3 sync <LOCAL_DIR>/ s3://<BUCKET_NAME>/ --storage-class STANDARD_IA
```

---
**Encryption & Versioning**
---

### **S3 Encryption**
- **Purpose:** Protects data by making it unreadable without proper keys.
- **Types:**
  - **SSE-S3:** Server-side, Amazon managed keys (AES-256).
  - **SSE-KMS:** Server-side, AWS Key Management Service, user-controlled keys.
  - **SSE-C:** Server-side, customer-provided keys.
  - **Client-Side Encryption:** Data encrypted before upload.
- **Usage:** Can be enabled per object or as a default for the bucket.

---

### **S3 Versioning**
- **Purpose:** Preserves, retrieves, and restores every version of an object.
- **Features:**
  - Protects against accidental overwrite/deletion.
  - Each update creates a new version.
  - Deleted objects can be restored (unless permanently deleted).
- **Usage:** Enable in bucket settings; can be suspended but not disabled.

---
> Enable both encryption and versioning for sensitive data to enhance security and recovery options.
---

**Enable versioning on a bucket**

Syntax:
```bash
  aws s3api put-bucket-versioning --bucket <BUCKET_NAME> --versioning-configuration Status=Enabled
```
Example:
```bash
  aws s3api put-bucket-versioning --bucket my-unique-bucket-0828 --versioning-configuration Status=Enabled
```

**Set default server-side encryption (AES256)**

Syntax:

Linux/Unix:
```bash
aws s3api put-bucket-encryption --bucket my-bucket \
  --server-side-encryption-configuration '{
    "Rules": [{
      "ApplyServerSideEncryptionByDefault": {"SSEAlgorithm": "AES256"}
    }]
  }'
```
PowerShell:
```powershell
aws s3api put-bucket-encryption --bucket my-bucket `
  --server-side-encryption-configuration "{`"Rules`":[{`"ApplyServerSideEncryptionByDefault`":{`"SSEAlgorithm`":`"AES256`"}}]}"
```

**Get encryption configuration**

Syntax:
```bash
  aws s3api get-bucket-encryption --bucket <BUCKET_NAME>
```

Example:
```bash
  aws s3api get-bucket-encryption --bucket my-unique-bucket-0828
```

**Upload file using KMS encryption**

Syntax:
```bash
  aws s3 cp <LOCAL_FILE> s3://<BUCKET_NAME>/ --sse aws:kms --sse-kms-key-id <KMS_KEY_ID>
```

---
**Working with Versioned Objects**

**Delete specific object version**

```bash
  aws s3api delete-object --bucket <BUCKET_NAME> --key <OBJECT_KEY> --version-id <VERSION_ID>
```

Example:
```bash
  aws s3api delete-object --bucket my-unique-bucket-0828 --key myphoto.png --version-id "3HL4kqtJlcpXrof3.c1pTF4S.XtRI9Xv"
```

---
**Debugging**

**List bucket contents with debug info**
```bash
  aws s3 ls s3://<BUCKET_NAME>/ --debug
```

Example:
```bash
  aws s3 ls s3://my-unique-bucket-0828/ --debug
```
---

**Tips:**
- Always confirm destructive actions (`--force`, `--recursive`) before running!
- Use versioning and encryption for security and data protection.
- Prefer API commands for scripting and automation; high-level commands (`aws s3 ...`) are convenient for quick tasks.

---
