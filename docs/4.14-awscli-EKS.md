# AWS CLI â€” EKS (Elastic Kubernetes Service) Operations Guide


> Replace sample cluster names, ARNs, account IDs (123456789012), regions (us-east-1), and versions (e.g., 1.30) with your own.
---

Sections:
1. Overview  
2. Quick Reference Variables  
3. Prerequisites & IAM Permissions  
4. Clusters (List / Describe / Create / Delete / Kubeconfig / Auth)  
5. Authentication (get-token, aws-auth ConfigMap notes)  
6. Cluster Logging & Control Plane Metrics  
7. Node Groups (List / Describe / Create / Update / Scale / Delete)  
8. Fargate Profiles  
9. Addon Management (Core & Managed Addons)  
10. Cluster Version & Upgrades  
11. OIDC & IRSA (IAM Roles for Service Accounts)  
12. Security (Endpoint Access / SG / Encryption)  
13. Networking (VPC CNI, Pod IPs, Prefix Delegation)  
14. Autoscaling Patterns (Karpenter / Cluster Autoscaler Overview)  
15. Observability (CloudWatch, Container Insights)  
16. Cost Awareness Tips  
17. Troubleshooting  
18. Automation Snippets  
19. Cleanup Sequences  
20. Best Practices Recap  
21. Notes & References  
22. Revision  

---

## 1. Overview
Amazon EKS provides managed Kubernetes control planes. You manage worker compute using:
- Managed Node Groups (EC2)
- Fargate Profiles (serverless pods)
- Add-ons (CNI, CoreDNS, kube-proxy, etc.)
- IAM for authentication (aws-auth ConfigMap)
- OIDC identity provider + IRSA for fine-grained pod IAM

AWS CLI commands (`aws eks`) complement `kubectl` for cluster-level operations.

---

## 2. Quick Reference Variables
```bash
export REGION=us-east-1
export ACCOUNT_ID=123456789012
export CLUSTER_NAME=dev-eks
export VERSION=1.30
export NODEGROUP=dev-ng-spot
export NODE_ROLE_ARN=arn:aws:iam::$ACCOUNT_ID:role/EKSNodeRole
export CLUSTER_ROLE_ARN=arn:aws:iam::$ACCOUNT_ID:role/EKSClusterRole
export SUBNETS=subnet-0ab1c2d3e4f567890,subnet-0123abcd4567ef890
export SECURITY_GROUP=sg-0123abcd4567ef890
export INSTANCE_TYPES=t3.medium
export DESIRED_SIZE=2
export MIN_SIZE=2
export MAX_SIZE=5
export FARGATE_PROFILE=fp-default
export NAMESPACE=default
export ADDON=coredns
```

---

## 3. Prerequisites & IAM Permissions
You (or CI role) need IAM permissions for:
- eks:CreateCluster / DescribeCluster / DeleteCluster / Update*
- eks:CreateNodegroup / eks:UpdateNodegroupConfig / eks:DeleteNodegroup
- iam:CreateRole / PassRole (for cluster + node roles)
- ec2:DescribeSubnets / CreateSecurityGroup (if provisioning)
- logs:CreateLogGroup (if enabling control plane logging)
- iam:CreateOpenIDConnectProvider (for IRSA)
- sts:AssumeRole (if cross-account)

Ensure VPC with at least two subnets in distinct AZs.

---

## 4. Clusters

### 4.1 List clusters
Syntax:
```bash
aws eks list-clusters --query 'clusters[]'
```
Example:
```bash
aws eks list-clusters --query 'clusters[]' --output table
```

### 4.2 Describe cluster
Syntax:
```bash
aws eks describe-cluster --name <CLUSTER_NAME>
```
Example (select fields):
```bash
aws eks describe-cluster --name $CLUSTER_NAME \
  --query 'cluster.{Name:name,Status:status,Version:version,Endpoint:endpoint,OIDC:identity.oidc.issuer}'
```

### 4.3 Create cluster (control plane only; data plane separate)
Syntax:
```bash
aws eks create-cluster \
  --name <CLUSTER_NAME> \
  --role-arn <CLUSTER_ROLE_ARN> \
  --resources-vpc-config subnetIds=<SUBNETS>,securityGroupIds=<SG_IDS> \
  --version <VERSION> \
  [--logging clusterLogging={types=[api,audit,authenticator,controllerManager,scheduler],enabled=true}]
```
Example (minimal):
```bash
aws eks create-cluster \
  --name $CLUSTER_NAME \
  --role-arn $CLUSTER_ROLE_ARN \
  --resources-vpc-config subnetIds=$SUBNETS,securityGroupIds=$SECURITY_GROUP \
  --version $VERSION
```

### 4.4 Wait for ACTIVE
```bash
aws eks wait cluster-active --name $CLUSTER_NAME
```

### 4.5 Update kubeconfig (write to ~/.kube/config)
Syntax:
```bash
aws eks update-kubeconfig --name <CLUSTER_NAME> [--region <REGION>] [--profile <PROFILE>]
```
Example:
```bash
aws eks update-kubeconfig --name $CLUSTER_NAME --region $REGION
kubectl get nodes
```

### 4.6 Delete cluster (must remove node groups/Fargate profiles first)
Syntax:
```bash
aws eks delete-cluster --name <CLUSTER_NAME>
```
Example:
```bash
aws eks delete-cluster --name $CLUSTER_NAME
aws eks wait cluster-deleted --name $CLUSTER_NAME
```

---

## 5. Authentication

### 5.1 Get cluster auth token (if kubectl not used)
Syntax:
```bash
aws eks get-token --cluster-name <CLUSTER_NAME>
```
Example:
```bash
aws eks get-token --cluster-name $CLUSTER_NAME --query 'status.token' --output text | cut -c1-60
```

### 5.2 aws-auth ConfigMap (concept)
The `aws-auth` ConfigMap in the `kube-system` namespace maps IAM roles/users to Kubernetes RBAC groups.
Retrieve (after kubeconfig is set):
```bash
kubectl -n kube-system get configmap aws-auth -o yaml
```
Add role mapping (edit):
```yaml
mapRoles: |
  - rolearn: arn:aws:iam::123456789012:role/DevOpsKubeAdmin
    username: devops-admin
    groups:
      - system:masters
```
(Apply changes via: `kubectl edit configmap aws-auth -n kube-system`)

---

## 6. Cluster Logging

### 6.1 Enable control plane logging (update cluster)
Syntax:
```bash
aws eks update-cluster-config \
  --name <CLUSTER_NAME> \
  --logging clusterLogging={types=[api,audit,authenticator,controllerManager,scheduler],enabled=true}
```
Example:
```bash
aws eks update-cluster-config \
  --name $CLUSTER_NAME \
  --logging clusterLogging='{types=[api,audit],enabled=true}'
```

### 6.2 Describe logging status
```bash
aws eks describe-cluster --name $CLUSTER_NAME \
  --query 'cluster.logging.clusterLogging'
```

---

## 7. Node Groups

### 7.1 List node groups
Syntax:
```bash
aws eks list-nodegroups --cluster-name <CLUSTER_NAME>
```
Example:
```bash
aws eks list-nodegroups --cluster-name $CLUSTER_NAME --query 'nodegroups[]'
```

### 7.2 Describe node group
Syntax:
```bash
aws eks describe-nodegroup --cluster-name <CLUSTER_NAME> --nodegroup-name <NODEGROUP_NAME>
```
Example:
```bash
aws eks describe-nodegroup --cluster-name $CLUSTER_NAME --nodegroup-name $NODEGROUP \
  --query 'nodegroup.{Status:status,Scaling:scalingConfig,InstanceTypes:instanceTypes,CapacityType:capacityType}'
```

### 7.3 Create managed node group
Syntax:
```bash
aws eks create-nodegroup \
  --cluster-name <CLUSTER_NAME> \
  --nodegroup-name <NODEGROUP_NAME> \
  --scaling-config minSize=<MIN>,maxSize=<MAX>,desiredSize=<DESIRED> \
  --disk-size <GB> \
  --subnets <SUBNET_IDS> \
  --instance-types <TYPE1>[,<TYPE2>] \
  --ami-type AL2_x86_64 \
  --node-role <NODE_INSTANCE_ROLE_ARN> \
  [--capacity-type SPOT|ON_DEMAND]
```
Example (spot mix):
```bash
aws eks create-nodegroup \
  --cluster-name $CLUSTER_NAME \
  --nodegroup-name $NODEGROUP \
  --scaling-config minSize=$MIN_SIZE,maxSize=$MAX_SIZE,desiredSize=$DESIRED_SIZE \
  --disk-size 40 \
  --subnets $SUBNETS \
  --instance-types $INSTANCE_TYPES \
  --ami-type AL2_x86_64 \
  --capacity-type SPOT \
  --node-role $NODE_ROLE_ARN
```

### 7.4 Wait node group active
```bash
aws eks wait nodegroup-active --cluster-name $CLUSTER_NAME --nodegroup-name $NODEGROUP
```

### 7.5 Update node group scaling
Syntax:
```bash
aws eks update-nodegroup-config \
  --cluster-name <CLUSTER_NAME> \
  --nodegroup-name <NODEGROUP_NAME> \
  --scaling-config minSize=<MIN>,maxSize=<MAX>,desiredSize=<DESIRED>
```
Example:
```bash
aws eks update-nodegroup-config \
  --cluster-name $CLUSTER_NAME \
  --nodegroup-name $NODEGROUP \
  --scaling-config minSize=2,maxSize=8,desiredSize=3
```

### 7.6 Update node group version / AMI
(Usually during cluster upgrade; EKS will manage when specified)
```bash
aws eks update-nodegroup-version \
  --cluster-name $CLUSTER_NAME \
  --nodegroup-name $NODEGROUP \
  --launch-template name=my-lt,version=2
```

### 7.7 Delete node group
Syntax:
```bash
aws eks delete-nodegroup --cluster-name <CLUSTER_NAME> --nodegroup-name <NODEGROUP_NAME>
```
Example:
```bash
aws eks delete-nodegroup --cluster-name $CLUSTER_NAME --nodegroup-name $NODEGROUP
aws eks wait nodegroup-deleted --cluster-name $CLUSTER_NAME --nodegroup-name $NODEGROUP
```

---

## 8. Fargate Profiles

### 8.1 List profiles
Syntax:
```bash
aws eks list-fargate-profiles --cluster-name <CLUSTER_NAME>
```
Example:
```bash
aws eks list-fargate-profiles --cluster-name $CLUSTER_NAME
```

### 8.2 Describe profile
```bash
aws eks describe-fargate-profile --cluster-name $CLUSTER_NAME --fargate-profile-name $FARGATE_PROFILE
```

### 8.3 Create Fargate profile
Syntax:
```bash
aws eks create-fargate-profile \
  --cluster-name <CLUSTER_NAME> \
  --fargate-profile-name <PROFILE_NAME> \
  --pod-execution-role-arn <ROLE_ARN> \
  --subnets <SUBNET_IDS> \
  --selectors namespace=<NAMESPACE>[,labels={k=v,...}]
```
Example:
```bash
aws eks create-fargate-profile \
  --cluster-name $CLUSTER_NAME \
  --fargate-profile-name $FARGATE_PROFILE \
  --pod-execution-role-arn arn:aws:iam::$ACCOUNT_ID:role/EKSPodExecutionRole \
  --subnets $SUBNETS \
  --selectors namespace=default
```

### 8.4 Delete profile
```bash
aws eks delete-fargate-profile --cluster-name $CLUSTER_NAME --fargate-profile-name $FARGATE_PROFILE
```

---

## 9. Addon Management

### 9.1 List addons
Syntax:
```bash
aws eks list-addons --cluster-name <CLUSTER_NAME>
```
Example:
```bash
aws eks list-addons --cluster-name $CLUSTER_NAME
```

### 9.2 Describe addon
Syntax:
```bash
aws eks describe-addon --cluster-name <CLUSTER_NAME> --addon-name <ADDON_NAME>
```
Example:
```bash
aws eks describe-addon --cluster-name $CLUSTER_NAME --addon-name $ADDON \
  --query 'addon.{Name:addonName,Version:addonVersion,Status:status}'
```

### 9.3 List available addon versions
```bash
aws eks describe-addon-versions --addon-name coredns \
  --query 'addons[0].addonVersions[].addonVersion'
```

### 9.4 Install addon
Syntax:
```bash
aws eks create-addon --cluster-name <CLUSTER_NAME> --addon-name <ADDON_NAME> [--addon-version <VER>] [--resolve-conflicts OVERWRITE]
```
Example:
```bash
aws eks create-addon --cluster-name $CLUSTER_NAME --addon-name kube-proxy
```

### 9.5 Update addon
```bash
aws eks update-addon \
  --cluster-name $CLUSTER_NAME \
  --addon-name coredns \
  --addon-version v1.11.1-eksbuild.2 \
  --resolve-conflicts OVERWRITE
```

### 9.6 Delete addon
```bash
aws eks delete-addon --cluster-name $CLUSTER_NAME --addon-name $ADDON
```

---

## 10. Cluster Version & Upgrades

### 10.1 Check current version
```bash
aws eks describe-cluster --name $CLUSTER_NAME --query 'cluster.version'
```

### 10.2 List supported platform versions
```bash
aws eks list-cluster-versions --query 'clusterVersions'
# (Note: Not all accounts have this API yet; alternatively consult docs)
```

### 10.3 Upgrade cluster control plane
Syntax:
```bash
aws eks update-cluster-version --name <CLUSTER_NAME> --version <VERSION>
```
Example:
```bash
aws eks update-cluster-version --name $CLUSTER_NAME --version 1.31
aws eks wait cluster-active --name $CLUSTER_NAME
```

### 10.4 Sequential process:
1. Upgrade control plane
2. Upgrade managed addons (CNI, CoreDNS, kube-proxy)
3. Upgrade node groups (rolling)
4. Verify workloads

---

## 11. OIDC & IRSA (IAM Roles for Service Accounts)

### 11.1 Get OIDC issuer
```bash
OIDC_ISSUER_URL=$(aws eks describe-cluster --name $CLUSTER_NAME --query 'cluster.identity.oidc.issuer' --output text)
echo $OIDC_ISSUER_URL
```

### 11.2 Create IAM OIDC provider (if not using eksctl convenience)
(Extract host-path)
```bash
PROVIDER_HOSTPATH=${OIDC_ISSUER_URL#https://}
aws iam create-open-id-connect-provider \
  --url $OIDC_ISSUER_URL \
  --client-id-list sts.amazonaws.com \
  --thumbprint-list 9e99a48a9960b14926bb7f3b02e22da0afd20f10
```
(Note: Thumbprint may vary; verify from AWS docs if changed.)

### 11.3 Create IAM policy for service account
`irsa-policy.json`:
```json
{
  "Version": "2012-10-17",
  "Statement": [{
    "Effect": "Allow",
    "Action": ["s3:ListBucket"],
    "Resource": ["arn:aws:s3:::my-app-bucket"]
  }]
}
```
```bash
aws iam create-policy --policy-name EKSListS3 --policy-document file://irsa-policy.json
```

### 11.4 Create role with trust policy referencing service account
`trust-irsa.json`:
```json
{
  "Version":"2012-10-17",
  "Statement":[{
    "Effect":"Allow",
    "Principal":{"Federated":"arn:aws:iam::123456789012:oidc-provider/oidc.eks.us-east-1.amazonaws.com/id/EXAMPLED539D4633E53DE1B716D3041E"},
    "Action":"sts:AssumeRoleWithWebIdentity",
    "Condition":{
      "StringEquals":{
        "oidc.eks.us-east-1.amazonaws.com/id/EXAMPLED539D4633E53DE1B716D3041E:sub":"system:serviceaccount:default:s3-reader"
      }
    }
  }]
}
```
Create:
```bash
aws iam create-role --role-name EKSS3ReaderRole --assume-role-policy-document file://trust-irsa.json
aws iam attach-role-policy --role-name EKSS3ReaderRole --policy-arn arn:aws:iam::$ACCOUNT_ID:policy/EKSListS3
```

### 11.5 Annotate service account (after kubeconfig)
```bash
kubectl create serviceaccount s3-reader
kubectl annotate serviceaccount s3-reader \
  eks.amazonaws.com/role-arn=arn:aws:iam::$ACCOUNT_ID:role/EKSS3ReaderRole
```

---

## 12. Security

### 12.1 Control plane endpoint access (public/private)
Syntax:
```bash
aws eks update-cluster-config \
  --name <CLUSTER_NAME> \
  --resources-vpc-config endpointPublicAccess=true,endpointPrivateAccess=false
```
Example:
```bash
aws eks update-cluster-config \
  --name $CLUSTER_NAME \
  --resources-vpc-config endpointPublicAccess=true,endpointPrivateAccess=true
```

### 12.2 Restrict public access CIDRs
```bash
aws eks update-cluster-config \
  --name $CLUSTER_NAME \
  --resources-vpc-config publicAccessCidrs=10.0.0.0/16
```

### 12.3 Encryption (create with KMS key)
(Only at create time for secrets encryption)
```bash
aws eks create-cluster \
  --name $CLUSTER_NAME \
  --role-arn $CLUSTER_ROLE_ARN \
  --resources-vpc-config subnetIds=$SUBNETS,securityGroupIds=$SECURITY_GROUP \
  --encryption-config 'resources=["secrets"],provider={keyArn=arn:aws:kms:us-east-1:123456789012:key/KEY-ID}' \
  --version $VERSION
```

---

## 13. Networking

### 13.1 Check CNI addon version
```bash
aws eks describe-addon --cluster-name $CLUSTER_NAME --addon-name vpc-cni \
  --query 'addon.addonVersion'
```

### 13.2 Enable prefix delegation (more IPs per ENI)
(For recent CNI versions) Set env on daemonset:
```bash
kubectl set env daemonset aws-node -n kube-system ENABLE_PREFIX_DELEGATION=true WARM_PREFIX_TARGET=1
```

### 13.3 View Pod CIDRs
```bash
aws eks describe-cluster --name $CLUSTER_NAME --query 'cluster.kubernetesNetworkConfig'
```

### 13.4 Get cluster security group
```bash
aws eks describe-cluster --name $CLUSTER_NAME --query 'cluster.resourcesVpcConfig.clusterSecurityGroupId'
```

---

## 14. Autoscaling Patterns

### 14.1 Cluster Autoscaler (concept)
Deploy via Helm or manifest with IRSA role allowing Describe* & scaling actions. (CLI example out-of-scope but referenced.)

### 14.2 Karpenter (concept)
Install Karpenter controller (IRSA + CRDs) then tune Provisioners for flexible capacity (not directly via `aws eks` CLI).

---

## 15. Observability

### 15.1 Enable Container Insights (CloudWatch)
(High-level: Install CloudWatch agent & Fluent Bit via Helm)
```bash
helm install cwagent cloudwatch-agent/cloudwatch-agent -n amazon-cloudwatch --create-namespace
```
(Shown for completeness; not an `aws eks` command.)

### 15.2 Control plane logs retrieval
Logs appear in CloudWatch Logs group: `/aws/eks/<cluster>/cluster`

---

## 16. Cost Awareness
- Use Spot node groups for non-critical, stateless workloads.
- Leverage Fargate for sporadic lightweight pods (avoid idle EC2).
- Right-size instance types; monitor CPU/memory via metrics.
- Remove unused addons and scale down node groups off-hours (scheduled).
- Evaluate Karpenter for bin-packing efficiency.
- Clean up old cluster versions & orphaned ENIs (after cluster deletion verify in VPC).

---

## 17. Troubleshooting
| Issue | Symptom | Likely Cause | Resolution |
|-------|---------|--------------|-----------|
| Cluster creation stuck | `CREATING` long time | Subnet / IAM / VPC endpoints missing | Check CloudTrail & events; validate IAM roles & subnets across AZs |
| `Unauthorized` in kubectl | Forbidden errors | aws-auth ConfigMap missing mapping | Add role/user mapping to `aws-auth` |
| Nodes NotReady | `kubectl get nodes` shows NotReady | CNI issues, IAM permissions for node role | Check `kubectl -n kube-system logs ds/aws-node`; ensure node role has AmazonEKS_CNI_Policy |
| Pod unschedulable | Pending pods | Insufficient capacity / taints | Scale node group, check pod requests/taints, enable autoscaler |
| IP exhaustion | Pod IP allocation fails | Low subnet free IPs | Add larger subnets / enable prefix delegation |
| Addon update failed | ADDON_FAILED status | Version conflict | Use `--resolve-conflicts OVERWRITE` or staged upgrade |
| OIDC / IRSA failure | Pod cannot access AWS API | Wrong trust condition or annotation | Verify service account annotation + trust policy `sub` |
| 403 on AWS SDK in pod | Access denied | IAM policy lacks action | Attach proper policy to IRSA role |
| `ThrottlingException` AWS APIs | Frequent autoscaler calls | Rate limits | Backoff or consolidate calls; ensure least privilege not causing retries |
| Kubeconfig expired token | Authentication error after time | Old token cached | Rerun `aws eks update-kubeconfig` or use `aws eks get-token` on each invocation |
| Fargate pod stuck | Pending state | Namespace/selector mismatch in profile | Confirm profile selectors + namespace labels |

---

## 18. Automation Snippets

### 18.1 Idempotent cluster ensure
```bash
if ! aws eks describe-cluster --name $CLUSTER_NAME >/dev/null 2>&1; then
  aws eks create-cluster \
    --name $CLUSTER_NAME \
    --role-arn $CLUSTER_ROLE_ARN \
    --resources-vpc-config subnetIds=$SUBNETS,securityGroupIds=$SECURITY_GROUP \
    --version $VERSION
  aws eks wait cluster-active --name $CLUSTER_NAME
fi
```

### 18.2 Rolling node group size bump + revert
```bash
OLD_DESIRED=$(aws eks describe-nodegroup --cluster-name $CLUSTER_NAME \
  --nodegroup-name $NODEGROUP --query 'nodegroup.scalingConfig.desiredSize' --output text)
aws eks update-nodegroup-config \
  --cluster-name $CLUSTER_NAME \
  --nodegroup-name $NODEGROUP \
  --scaling-config minSize=$MIN_SIZE,maxSize=$MAX_SIZE,desiredSize=$((OLD_DESIRED+1))
# ... perform maintenance ...
aws eks update-nodegroup-config \
  --cluster-name $CLUSTER_NAME \
  --nodegroup-name $NODEGROUP \
  --scaling-config minSize=$MIN_SIZE,maxSize=$MAX_SIZE,desiredSize=$OLD_DESIRED
```

### 18.3 Simple cluster version drift check
```bash
CUR=$(aws eks describe-cluster --name $CLUSTER_NAME --query 'cluster.version' --output text)
TARGET=1.31
if [ "$CUR" != "$TARGET" ]; then
  echo "Upgrading $CLUSTER_NAME from $CUR to $TARGET"
  aws eks update-cluster-version --name $CLUSTER_NAME --version $TARGET
fi
```

### 18.4 List addons with status
```bash
for A in $(aws eks list-addons --cluster-name $CLUSTER_NAME --query 'addons[]' --output text); do
  aws eks describe-addon --cluster-name $CLUSTER_NAME --addon-name $A \
    --query 'addon.{Name:addonName,Version:addonVersion,Status:status}'
done
```

---

## 19. Cleanup Sequences

### 19.1 Delete Fargate profiles
```bash
for FP in $(aws eks list-fargate-profiles --cluster-name $CLUSTER_NAME --query 'fargateProfileNames[]' --output text); do
  aws eks delete-fargate-profile --cluster-name $CLUSTER_NAME --fargate-profile-name $FP
  aws eks wait fargate-profile-deleted --cluster-name $CLUSTER_NAME --fargate-profile-name $FP
done
```

### 19.2 Delete node groups
```bash
for NG in $(aws eks list-nodegroups --cluster-name $CLUSTER_NAME --query 'nodegroups[]' --output text); do
  aws eks delete-nodegroup --cluster-name $CLUSTER_NAME --nodegroup-name $NG
  aws eks wait nodegroup-deleted --cluster-name $CLUSTER_NAME --nodegroup-name $NG
done
```

### 19.3 Delete addons
```bash
for AD in $(aws eks list-addons --cluster-name $CLUSTER_NAME --query 'addons[]' --output text); do
  aws eks delete-addon --cluster-name $CLUSTER_NAME --addon-name $AD
done
```

### 19.4 Delete cluster
```bash
aws eks delete-cluster --name $CLUSTER_NAME
aws eks wait cluster-deleted --name $CLUSTER_NAME
```

### 19.5 Delete OIDC provider (manual)
```bash
OIDC_URL=$(aws eks describe-cluster --name $CLUSTER_NAME --query 'cluster.identity.oidc.issuer' --output text 2>/dev/null || true)
if [ -n "$OIDC_URL" ]; then
  PROVIDER=$(aws iam list-open-id-connect-providers --query 'OpenIDConnectProviderList[].Arn' --output text | tr '\t' '\n' | grep "${OIDC_URL#https://}" || true)
  [ -n "$PROVIDER" ] && aws iam delete-open-id-connect-provider --open-id-connect-provider-arn "$PROVIDER"
fi
```

---

## 20. Best Practices Recap
- Keep EKS control plane version close to the latest (stay within the supported window).
- Use IRSA for pod-level least privilege; avoid node role over-permission.
- Enable control plane logging for audit & security.
- Monitor CNI IP usage; plan subnet sizing generously or enable prefix delegation.
- Separate workloads by node group (e.g., Spot vs OnDemand, GPU vs general).
- Use managed addons for consistent patching; monitor versions.
- Tag clusters & node groups (Owner, Env, CostCenter).
- Implement autoscaling (Cluster Autoscaler or Karpenter) to optimize capacity.
- Encrypt secrets with the KMS key at cluster creation for compliance.
- Regularly prune unused IAM roles tied to retired service accounts.

---

## 21. Notes & References
- Some features (e.g., list-cluster-versions) may vary by CLI version/region.
- EKS pricing: Control plane flat hourly fee + resource costs (EC2 / Fargate).
- For a private-only endpoint, ensure a bastion or SSM Session to run kubectl.
- Addons often map to Kubernetes components (vpc-cni, coredns, kube-proxy, aws-ebs-csi-driver).
- Use `kubectl top nodes/pods` (requires Metrics Server) for right-sizing.
- Documentation:
  - EKS User Guide: https://docs.aws.amazon.com/eks/latest/userguide
  - IRSA: https://docs.aws.amazon.com/eks/latest/userguide/iam-roles-for-service-accounts.html
  - Addons: https://docs.aws.amazon.com/eks/latest/userguide/eks-add-ons.html

---
